{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "from torchvision.ops import MultiScaleRoIAlign\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision.models.detection.transform  import  GeneralizedRCNNTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch GAF_2 Training')\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "EPOCH = 50   \n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop((800,800)),\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((800,800)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "trainset = ImageFolder(root='../GAF_2_Data/Train/', transform=transform_train) \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True, num_workers=256)   \n",
    "\n",
    "testset = ImageFolder(root='../GAF_2_Data/Val/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=256)\n",
    "\n",
    "classes = ('Negative', 'Neutral', 'Positive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Net, self).__init__()\n",
    "        self.backbone = model\n",
    "        self.fc1_layer = nn.Sequential(nn.Linear(in_features=12544, out_features=1024),nn.ReLU())\n",
    "        self.fc2_layer = nn.Linear(in_features=1024, out_features=3) \n",
    "        self.box_roi_pool = MultiScaleRoIAlign(\n",
    "                featmap_names=['0', '1', '2', '3'],\n",
    "                output_size=7,\n",
    "                sampling_ratio=2)\n",
    "    def forward(self, x):\n",
    "        w = x.shape[-2]\n",
    "        h = x.shape[-1]\n",
    "        x = self.backbone(x)\n",
    "        boxes = torch.zeros(x['0'].shape[0],4).to(device)\n",
    "        boxes[:,2] = w-1\n",
    "        boxes[:,3] = h-1\n",
    "        x = self.box_roi_pool(x, [boxes], [(w, h)])\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1_layer(x)\n",
    "        x = self.fc2_layer(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.backbone_utils.resnet_fpn_backbone(\"resnet50\", pretrained=True,trainable_layers=5)\n",
    "net = Net(model)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): FrozenBatchNorm2d(64)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(256)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(512)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(1024)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(2048)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (fc1_layer): Sequential(\n",
      "    (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2_layer): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (box_roi_pool): MultiScaleRoIAlign()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training, Resnet50-FPN!\n",
      "\n",
      "Epoch: 1\n",
      "[epoch:1, iter:1] Loss: 1.129 | Acc: 0.000% \n",
      "[epoch:1, iter:2] Loss: 1.121 | Acc: 0.000% \n",
      "[epoch:1, iter:3] Loss: 1.127 | Acc: 0.000% \n",
      "[epoch:1, iter:4] Loss: 1.134 | Acc: 0.000% \n",
      "[epoch:1, iter:5] Loss: 1.133 | Acc: 0.000% \n",
      "[epoch:1, iter:6] Loss: 1.128 | Acc: 0.000% \n",
      "[epoch:1, iter:7] Loss: 1.127 | Acc: 0.000% \n",
      "[epoch:1, iter:8] Loss: 1.124 | Acc: 0.000% \n",
      "[epoch:1, iter:9] Loss: 1.120 | Acc: 11.111% \n",
      "[epoch:1, iter:10] Loss: 1.115 | Acc: 20.000% \n",
      "[epoch:1, iter:11] Loss: 1.113 | Acc: 18.182% \n",
      "[epoch:1, iter:12] Loss: 1.110 | Acc: 25.000% \n",
      "[epoch:1, iter:13] Loss: 1.110 | Acc: 23.077% \n",
      "[epoch:1, iter:14] Loss: 1.108 | Acc: 28.571% \n",
      "[epoch:1, iter:15] Loss: 1.106 | Acc: 33.333% \n",
      "[epoch:1, iter:16] Loss: 1.106 | Acc: 31.250% \n",
      "[epoch:1, iter:17] Loss: 1.101 | Acc: 35.294% \n",
      "[epoch:1, iter:18] Loss: 1.101 | Acc: 33.333% \n",
      "[epoch:1, iter:19] Loss: 1.099 | Acc: 31.579% \n",
      "[epoch:1, iter:20] Loss: 1.098 | Acc: 35.000% \n",
      "[epoch:1, iter:21] Loss: 1.099 | Acc: 33.333% \n",
      "[epoch:1, iter:22] Loss: 1.099 | Acc: 31.818% \n",
      "[epoch:1, iter:23] Loss: 1.102 | Acc: 30.435% \n",
      "[epoch:1, iter:24] Loss: 1.101 | Acc: 29.167% \n",
      "[epoch:1, iter:25] Loss: 1.105 | Acc: 28.000% \n",
      "[epoch:1, iter:26] Loss: 1.104 | Acc: 26.923% \n",
      "[epoch:1, iter:27] Loss: 1.107 | Acc: 25.926% \n",
      "[epoch:1, iter:28] Loss: 1.105 | Acc: 28.571% \n",
      "[epoch:1, iter:29] Loss: 1.106 | Acc: 27.586% \n",
      "[epoch:1, iter:30] Loss: 1.107 | Acc: 26.667% \n",
      "[epoch:1, iter:31] Loss: 1.107 | Acc: 25.806% \n",
      "[epoch:1, iter:32] Loss: 1.106 | Acc: 25.000% \n",
      "[epoch:1, iter:33] Loss: 1.108 | Acc: 24.242% \n",
      "[epoch:1, iter:34] Loss: 1.108 | Acc: 23.529% \n",
      "[epoch:1, iter:35] Loss: 1.107 | Acc: 22.857% \n",
      "[epoch:1, iter:36] Loss: 1.106 | Acc: 25.000% \n",
      "[epoch:1, iter:37] Loss: 1.104 | Acc: 27.027% \n",
      "[epoch:1, iter:38] Loss: 1.104 | Acc: 26.316% \n",
      "[epoch:1, iter:39] Loss: 1.105 | Acc: 25.641% \n",
      "[epoch:1, iter:40] Loss: 1.106 | Acc: 25.000% \n",
      "[epoch:1, iter:41] Loss: 1.104 | Acc: 26.829% \n",
      "[epoch:1, iter:42] Loss: 1.102 | Acc: 28.571% \n",
      "[epoch:1, iter:43] Loss: 1.102 | Acc: 27.907% \n",
      "[epoch:1, iter:44] Loss: 1.100 | Acc: 29.545% \n",
      "[epoch:1, iter:45] Loss: 1.100 | Acc: 28.889% \n",
      "[epoch:1, iter:46] Loss: 1.101 | Acc: 28.261% \n",
      "[epoch:1, iter:47] Loss: 1.101 | Acc: 27.660% \n",
      "[epoch:1, iter:48] Loss: 1.099 | Acc: 29.167% \n",
      "[epoch:1, iter:49] Loss: 1.099 | Acc: 28.571% \n",
      "[epoch:1, iter:50] Loss: 1.099 | Acc: 28.000% \n",
      "[epoch:1, iter:51] Loss: 1.100 | Acc: 27.451% \n",
      "[epoch:1, iter:52] Loss: 1.099 | Acc: 28.846% \n",
      "[epoch:1, iter:53] Loss: 1.102 | Acc: 28.302% \n",
      "[epoch:1, iter:54] Loss: 1.104 | Acc: 27.778% \n",
      "[epoch:1, iter:55] Loss: 1.105 | Acc: 27.273% \n",
      "[epoch:1, iter:56] Loss: 1.105 | Acc: 26.786% \n",
      "[epoch:1, iter:57] Loss: 1.106 | Acc: 26.316% \n",
      "[epoch:1, iter:58] Loss: 1.105 | Acc: 27.586% \n",
      "[epoch:1, iter:59] Loss: 1.105 | Acc: 27.119% \n",
      "[epoch:1, iter:60] Loss: 1.106 | Acc: 26.667% \n",
      "[epoch:1, iter:61] Loss: 1.105 | Acc: 27.869% \n",
      "[epoch:1, iter:62] Loss: 1.105 | Acc: 27.419% \n",
      "[epoch:1, iter:63] Loss: 1.105 | Acc: 26.984% \n",
      "[epoch:1, iter:64] Loss: 1.105 | Acc: 26.562% \n",
      "[epoch:1, iter:65] Loss: 1.106 | Acc: 26.154% \n",
      "[epoch:1, iter:66] Loss: 1.106 | Acc: 25.758% \n",
      "[epoch:1, iter:67] Loss: 1.105 | Acc: 25.373% \n",
      "[epoch:1, iter:68] Loss: 1.105 | Acc: 25.000% \n",
      "[epoch:1, iter:69] Loss: 1.105 | Acc: 26.087% \n",
      "[epoch:1, iter:70] Loss: 1.105 | Acc: 25.714% \n",
      "[epoch:1, iter:71] Loss: 1.104 | Acc: 26.761% \n",
      "[epoch:1, iter:72] Loss: 1.104 | Acc: 27.778% \n",
      "[epoch:1, iter:73] Loss: 1.104 | Acc: 27.397% \n",
      "[epoch:1, iter:74] Loss: 1.104 | Acc: 28.378% \n",
      "[epoch:1, iter:75] Loss: 1.103 | Acc: 29.333% \n",
      "[epoch:1, iter:76] Loss: 1.103 | Acc: 28.947% \n",
      "[epoch:1, iter:77] Loss: 1.102 | Acc: 29.870% \n",
      "[epoch:1, iter:78] Loss: 1.102 | Acc: 29.487% \n",
      "[epoch:1, iter:79] Loss: 1.102 | Acc: 29.114% \n",
      "[epoch:1, iter:80] Loss: 1.103 | Acc: 28.750% \n",
      "[epoch:1, iter:81] Loss: 1.103 | Acc: 29.630% \n",
      "[epoch:1, iter:82] Loss: 1.102 | Acc: 30.488% \n",
      "[epoch:1, iter:83] Loss: 1.102 | Acc: 31.325% \n",
      "[epoch:1, iter:84] Loss: 1.102 | Acc: 30.952% \n",
      "[epoch:1, iter:85] Loss: 1.101 | Acc: 31.765% \n",
      "[epoch:1, iter:86] Loss: 1.101 | Acc: 31.395% \n",
      "[epoch:1, iter:87] Loss: 1.101 | Acc: 31.034% \n",
      "[epoch:1, iter:88] Loss: 1.101 | Acc: 31.818% \n",
      "[epoch:1, iter:89] Loss: 1.100 | Acc: 32.584% \n",
      "[epoch:1, iter:90] Loss: 1.101 | Acc: 32.222% \n",
      "[epoch:1, iter:91] Loss: 1.102 | Acc: 31.868% \n",
      "[epoch:1, iter:92] Loss: 1.102 | Acc: 31.522% \n",
      "[epoch:1, iter:93] Loss: 1.101 | Acc: 32.258% \n",
      "[epoch:1, iter:94] Loss: 1.101 | Acc: 32.979% \n",
      "[epoch:1, iter:95] Loss: 1.101 | Acc: 32.632% \n",
      "[epoch:1, iter:96] Loss: 1.101 | Acc: 32.292% \n",
      "[epoch:1, iter:97] Loss: 1.101 | Acc: 32.990% \n",
      "[epoch:1, iter:98] Loss: 1.102 | Acc: 32.653% \n",
      "[epoch:1, iter:99] Loss: 1.102 | Acc: 32.323% \n",
      "[epoch:1, iter:100] Loss: 1.102 | Acc: 32.000% \n",
      "[epoch:1, iter:101] Loss: 1.102 | Acc: 31.683% \n",
      "[epoch:1, iter:102] Loss: 1.101 | Acc: 32.353% \n",
      "[epoch:1, iter:103] Loss: 1.102 | Acc: 32.039% \n",
      "[epoch:1, iter:104] Loss: 1.102 | Acc: 31.731% \n",
      "[epoch:1, iter:105] Loss: 1.102 | Acc: 31.429% \n",
      "[epoch:1, iter:106] Loss: 1.102 | Acc: 31.132% \n",
      "[epoch:1, iter:107] Loss: 1.102 | Acc: 30.841% \n",
      "[epoch:1, iter:108] Loss: 1.102 | Acc: 30.556% \n",
      "[epoch:1, iter:109] Loss: 1.102 | Acc: 31.193% \n",
      "[epoch:1, iter:110] Loss: 1.101 | Acc: 31.818% \n",
      "[epoch:1, iter:111] Loss: 1.102 | Acc: 31.532% \n",
      "[epoch:1, iter:112] Loss: 1.102 | Acc: 31.250% \n",
      "[epoch:1, iter:113] Loss: 1.101 | Acc: 31.858% \n",
      "[epoch:1, iter:114] Loss: 1.101 | Acc: 31.579% \n",
      "[epoch:1, iter:115] Loss: 1.101 | Acc: 32.174% \n",
      "[epoch:1, iter:116] Loss: 1.101 | Acc: 31.897% \n",
      "[epoch:1, iter:117] Loss: 1.101 | Acc: 31.624% \n",
      "[epoch:1, iter:118] Loss: 1.100 | Acc: 32.203% \n",
      "[epoch:1, iter:119] Loss: 1.101 | Acc: 31.933% \n",
      "[epoch:1, iter:120] Loss: 1.101 | Acc: 32.500% \n",
      "[epoch:1, iter:121] Loss: 1.101 | Acc: 32.231% \n",
      "[epoch:1, iter:122] Loss: 1.102 | Acc: 31.967% \n",
      "[epoch:1, iter:123] Loss: 1.102 | Acc: 31.707% \n",
      "[epoch:1, iter:124] Loss: 1.103 | Acc: 31.452% \n",
      "[epoch:1, iter:125] Loss: 1.103 | Acc: 31.200% \n",
      "[epoch:1, iter:126] Loss: 1.103 | Acc: 30.952% \n",
      "[epoch:1, iter:127] Loss: 1.103 | Acc: 30.709% \n",
      "[epoch:1, iter:128] Loss: 1.103 | Acc: 31.250% \n",
      "[epoch:1, iter:129] Loss: 1.103 | Acc: 31.783% \n",
      "[epoch:1, iter:130] Loss: 1.103 | Acc: 32.308% \n",
      "[epoch:1, iter:131] Loss: 1.103 | Acc: 32.061% \n",
      "[epoch:1, iter:132] Loss: 1.103 | Acc: 32.576% \n",
      "[epoch:1, iter:133] Loss: 1.103 | Acc: 32.331% \n",
      "[epoch:1, iter:134] Loss: 1.102 | Acc: 32.836% \n",
      "[epoch:1, iter:135] Loss: 1.102 | Acc: 33.333% \n",
      "[epoch:1, iter:136] Loss: 1.102 | Acc: 33.824% \n",
      "[epoch:1, iter:137] Loss: 1.102 | Acc: 33.577% \n",
      "[epoch:1, iter:138] Loss: 1.102 | Acc: 34.058% \n",
      "[epoch:1, iter:139] Loss: 1.102 | Acc: 33.813% \n",
      "[epoch:1, iter:140] Loss: 1.102 | Acc: 33.571% \n",
      "[epoch:1, iter:141] Loss: 1.101 | Acc: 34.043% \n",
      "[epoch:1, iter:142] Loss: 1.102 | Acc: 33.803% \n",
      "[epoch:1, iter:143] Loss: 1.102 | Acc: 33.566% \n",
      "[epoch:1, iter:144] Loss: 1.102 | Acc: 33.333% \n",
      "[epoch:1, iter:145] Loss: 1.102 | Acc: 33.103% \n",
      "[epoch:1, iter:146] Loss: 1.102 | Acc: 33.562% \n",
      "[epoch:1, iter:147] Loss: 1.101 | Acc: 34.014% \n",
      "[epoch:1, iter:148] Loss: 1.101 | Acc: 34.459% \n",
      "[epoch:1, iter:149] Loss: 1.101 | Acc: 34.228% \n",
      "[epoch:1, iter:150] Loss: 1.101 | Acc: 34.000% \n",
      "[epoch:1, iter:151] Loss: 1.101 | Acc: 33.775% \n",
      "[epoch:1, iter:152] Loss: 1.101 | Acc: 33.553% \n",
      "[epoch:1, iter:153] Loss: 1.101 | Acc: 33.333% \n",
      "[epoch:1, iter:154] Loss: 1.101 | Acc: 33.117% \n",
      "[epoch:1, iter:155] Loss: 1.101 | Acc: 33.548% \n",
      "[epoch:1, iter:156] Loss: 1.101 | Acc: 33.333% \n",
      "[epoch:1, iter:157] Loss: 1.102 | Acc: 33.121% \n",
      "[epoch:1, iter:158] Loss: 1.102 | Acc: 32.911% \n",
      "[epoch:1, iter:159] Loss: 1.102 | Acc: 33.333% \n",
      "[epoch:1, iter:160] Loss: 1.102 | Acc: 33.125% \n",
      "[epoch:1, iter:161] Loss: 1.102 | Acc: 33.540% \n",
      "[epoch:1, iter:162] Loss: 1.102 | Acc: 33.333% \n",
      "[epoch:1, iter:163] Loss: 1.102 | Acc: 33.129% \n",
      "[epoch:1, iter:164] Loss: 1.102 | Acc: 33.537% \n",
      "[epoch:1, iter:165] Loss: 1.101 | Acc: 33.939% \n",
      "[epoch:1, iter:166] Loss: 1.100 | Acc: 34.337% \n",
      "[epoch:1, iter:167] Loss: 1.100 | Acc: 34.731% \n",
      "[epoch:1, iter:168] Loss: 1.101 | Acc: 34.524% \n",
      "[epoch:1, iter:169] Loss: 1.100 | Acc: 34.911% \n",
      "[epoch:1, iter:170] Loss: 1.099 | Acc: 35.294% \n",
      "[epoch:1, iter:171] Loss: 1.100 | Acc: 35.088% \n",
      "[epoch:1, iter:172] Loss: 1.100 | Acc: 34.884% \n",
      "[epoch:1, iter:173] Loss: 1.100 | Acc: 34.682% \n",
      "[epoch:1, iter:174] Loss: 1.100 | Acc: 35.057% \n",
      "[epoch:1, iter:175] Loss: 1.099 | Acc: 35.429% \n",
      "[epoch:1, iter:176] Loss: 1.099 | Acc: 35.227% \n",
      "[epoch:1, iter:177] Loss: 1.100 | Acc: 35.028% \n",
      "[epoch:1, iter:178] Loss: 1.100 | Acc: 34.831% \n",
      "[epoch:1, iter:179] Loss: 1.099 | Acc: 35.196% \n",
      "[epoch:1, iter:180] Loss: 1.099 | Acc: 35.000% \n",
      "[epoch:1, iter:181] Loss: 1.099 | Acc: 35.359% \n",
      "[epoch:1, iter:182] Loss: 1.098 | Acc: 35.714% \n",
      "[epoch:1, iter:183] Loss: 1.097 | Acc: 36.066% \n",
      "[epoch:1, iter:184] Loss: 1.096 | Acc: 36.413% \n",
      "[epoch:1, iter:185] Loss: 1.097 | Acc: 36.216% \n",
      "[epoch:1, iter:186] Loss: 1.098 | Acc: 36.022% \n",
      "[epoch:1, iter:187] Loss: 1.098 | Acc: 35.829% \n",
      "[epoch:1, iter:188] Loss: 1.097 | Acc: 36.170% \n",
      "[epoch:1, iter:189] Loss: 1.098 | Acc: 35.979% \n",
      "[epoch:1, iter:190] Loss: 1.099 | Acc: 35.789% \n",
      "[epoch:1, iter:191] Loss: 1.098 | Acc: 36.126% \n",
      "[epoch:1, iter:192] Loss: 1.099 | Acc: 35.938% \n",
      "[epoch:1, iter:193] Loss: 1.099 | Acc: 35.751% \n",
      "[epoch:1, iter:194] Loss: 1.100 | Acc: 35.567% \n",
      "[epoch:1, iter:195] Loss: 1.099 | Acc: 35.897% \n",
      "[epoch:1, iter:196] Loss: 1.099 | Acc: 35.714% \n",
      "[epoch:1, iter:197] Loss: 1.099 | Acc: 36.041% \n",
      "[epoch:1, iter:198] Loss: 1.099 | Acc: 35.859% \n",
      "[epoch:1, iter:199] Loss: 1.099 | Acc: 36.181% \n",
      "[epoch:1, iter:200] Loss: 1.098 | Acc: 36.500% \n",
      "[epoch:1, iter:201] Loss: 1.098 | Acc: 36.318% \n",
      "[epoch:1, iter:202] Loss: 1.098 | Acc: 36.634% \n",
      "[epoch:1, iter:203] Loss: 1.098 | Acc: 36.453% \n",
      "[epoch:1, iter:204] Loss: 1.097 | Acc: 36.765% \n",
      "[epoch:1, iter:205] Loss: 1.098 | Acc: 36.585% \n",
      "[epoch:1, iter:206] Loss: 1.098 | Acc: 36.408% \n",
      "[epoch:1, iter:207] Loss: 1.097 | Acc: 36.715% \n",
      "[epoch:1, iter:208] Loss: 1.098 | Acc: 36.538% \n",
      "[epoch:1, iter:209] Loss: 1.098 | Acc: 36.364% \n",
      "[epoch:1, iter:210] Loss: 1.097 | Acc: 36.667% \n",
      "[epoch:1, iter:211] Loss: 1.097 | Acc: 36.967% \n",
      "[epoch:1, iter:212] Loss: 1.096 | Acc: 37.264% \n",
      "[epoch:1, iter:213] Loss: 1.097 | Acc: 37.089% \n",
      "[epoch:1, iter:214] Loss: 1.097 | Acc: 36.916% \n",
      "[epoch:1, iter:215] Loss: 1.097 | Acc: 36.744% \n",
      "[epoch:1, iter:216] Loss: 1.098 | Acc: 36.574% \n",
      "[epoch:1, iter:217] Loss: 1.098 | Acc: 36.406% \n",
      "[epoch:1, iter:218] Loss: 1.098 | Acc: 36.697% \n",
      "[epoch:1, iter:219] Loss: 1.097 | Acc: 36.986% \n",
      "[epoch:1, iter:220] Loss: 1.098 | Acc: 36.818% \n",
      "[epoch:1, iter:221] Loss: 1.097 | Acc: 37.104% \n",
      "[epoch:1, iter:222] Loss: 1.096 | Acc: 37.387% \n",
      "[epoch:1, iter:223] Loss: 1.097 | Acc: 37.220% \n",
      "[epoch:1, iter:224] Loss: 1.096 | Acc: 37.500% \n",
      "[epoch:1, iter:225] Loss: 1.095 | Acc: 37.778% \n",
      "[epoch:1, iter:226] Loss: 1.096 | Acc: 37.611% \n",
      "[epoch:1, iter:227] Loss: 1.095 | Acc: 37.885% \n",
      "[epoch:1, iter:228] Loss: 1.095 | Acc: 37.719% \n",
      "[epoch:1, iter:229] Loss: 1.094 | Acc: 37.991% \n",
      "[epoch:1, iter:230] Loss: 1.095 | Acc: 37.826% \n",
      "[epoch:1, iter:231] Loss: 1.094 | Acc: 38.095% \n",
      "[epoch:1, iter:232] Loss: 1.093 | Acc: 38.362% \n",
      "[epoch:1, iter:233] Loss: 1.094 | Acc: 38.197% \n",
      "[epoch:1, iter:234] Loss: 1.093 | Acc: 38.462% \n",
      "[epoch:1, iter:235] Loss: 1.094 | Acc: 38.298% \n",
      "[epoch:1, iter:236] Loss: 1.094 | Acc: 38.136% \n",
      "[epoch:1, iter:237] Loss: 1.093 | Acc: 38.397% \n",
      "[epoch:1, iter:238] Loss: 1.094 | Acc: 38.235% \n",
      "[epoch:1, iter:239] Loss: 1.093 | Acc: 38.494% \n",
      "[epoch:1, iter:240] Loss: 1.092 | Acc: 38.750% \n",
      "[epoch:1, iter:241] Loss: 1.093 | Acc: 38.589% \n",
      "[epoch:1, iter:242] Loss: 1.093 | Acc: 38.430% \n",
      "[epoch:1, iter:243] Loss: 1.094 | Acc: 38.272% \n",
      "[epoch:1, iter:244] Loss: 1.094 | Acc: 38.115% \n",
      "[epoch:1, iter:245] Loss: 1.093 | Acc: 38.367% \n",
      "[epoch:1, iter:246] Loss: 1.092 | Acc: 38.618% \n",
      "[epoch:1, iter:247] Loss: 1.093 | Acc: 38.462% \n",
      "[epoch:1, iter:248] Loss: 1.092 | Acc: 38.710% \n",
      "[epoch:1, iter:249] Loss: 1.093 | Acc: 38.554% \n",
      "[epoch:1, iter:250] Loss: 1.092 | Acc: 38.800% \n",
      "[epoch:1, iter:251] Loss: 1.091 | Acc: 39.044% \n",
      "[epoch:1, iter:252] Loss: 1.092 | Acc: 38.889% \n",
      "[epoch:1, iter:253] Loss: 1.093 | Acc: 38.735% \n",
      "[epoch:1, iter:254] Loss: 1.093 | Acc: 38.583% \n",
      "[epoch:1, iter:255] Loss: 1.094 | Acc: 38.431% \n",
      "[epoch:1, iter:256] Loss: 1.094 | Acc: 38.281% \n",
      "[epoch:1, iter:257] Loss: 1.093 | Acc: 38.521% \n",
      "[epoch:1, iter:258] Loss: 1.093 | Acc: 38.760% \n",
      "[epoch:1, iter:259] Loss: 1.093 | Acc: 38.610% \n",
      "[epoch:1, iter:260] Loss: 1.093 | Acc: 38.462% \n",
      "[epoch:1, iter:261] Loss: 1.094 | Acc: 38.314% \n",
      "[epoch:1, iter:262] Loss: 1.095 | Acc: 38.168% \n",
      "[epoch:1, iter:263] Loss: 1.095 | Acc: 38.023% \n",
      "[epoch:1, iter:264] Loss: 1.095 | Acc: 37.879% \n",
      "[epoch:1, iter:265] Loss: 1.096 | Acc: 37.736% \n",
      "[epoch:1, iter:266] Loss: 1.095 | Acc: 37.970% \n",
      "[epoch:1, iter:267] Loss: 1.094 | Acc: 38.202% \n",
      "[epoch:1, iter:268] Loss: 1.094 | Acc: 38.433% \n",
      "[epoch:1, iter:269] Loss: 1.094 | Acc: 38.290% \n",
      "[epoch:1, iter:270] Loss: 1.094 | Acc: 38.519% \n",
      "[epoch:1, iter:271] Loss: 1.094 | Acc: 38.376% \n",
      "[epoch:1, iter:272] Loss: 1.095 | Acc: 38.235% \n",
      "[epoch:1, iter:273] Loss: 1.095 | Acc: 38.095% \n",
      "[epoch:1, iter:274] Loss: 1.095 | Acc: 38.321% \n",
      "[epoch:1, iter:275] Loss: 1.095 | Acc: 38.182% \n",
      "[epoch:1, iter:276] Loss: 1.095 | Acc: 38.043% \n",
      "[epoch:1, iter:277] Loss: 1.095 | Acc: 38.267% \n",
      "[epoch:1, iter:278] Loss: 1.095 | Acc: 38.129% \n",
      "[epoch:1, iter:279] Loss: 1.095 | Acc: 37.993% \n",
      "[epoch:1, iter:280] Loss: 1.096 | Acc: 37.857% \n",
      "[epoch:1, iter:281] Loss: 1.096 | Acc: 37.722% \n",
      "[epoch:1, iter:282] Loss: 1.096 | Acc: 37.589% \n",
      "[epoch:1, iter:283] Loss: 1.096 | Acc: 37.809% \n",
      "[epoch:1, iter:284] Loss: 1.096 | Acc: 38.028% \n",
      "[epoch:1, iter:285] Loss: 1.096 | Acc: 37.895% \n",
      "[epoch:1, iter:286] Loss: 1.096 | Acc: 37.762% \n",
      "[epoch:1, iter:287] Loss: 1.096 | Acc: 37.979% \n",
      "[epoch:1, iter:288] Loss: 1.095 | Acc: 38.194% \n",
      "[epoch:1, iter:289] Loss: 1.095 | Acc: 38.062% \n",
      "[epoch:1, iter:290] Loss: 1.095 | Acc: 38.276% \n",
      "[epoch:1, iter:291] Loss: 1.094 | Acc: 38.488% \n",
      "[epoch:1, iter:292] Loss: 1.095 | Acc: 38.356% \n",
      "[epoch:1, iter:293] Loss: 1.094 | Acc: 38.567% \n",
      "[epoch:1, iter:294] Loss: 1.094 | Acc: 38.776% \n",
      "[epoch:1, iter:295] Loss: 1.094 | Acc: 38.644% \n",
      "[epoch:1, iter:296] Loss: 1.094 | Acc: 38.514% \n",
      "[epoch:1, iter:297] Loss: 1.095 | Acc: 38.384% \n",
      "[epoch:1, iter:298] Loss: 1.094 | Acc: 38.591% \n",
      "[epoch:1, iter:299] Loss: 1.094 | Acc: 38.462% \n",
      "[epoch:1, iter:300] Loss: 1.094 | Acc: 38.333% \n",
      "[epoch:1, iter:301] Loss: 1.094 | Acc: 38.206% \n",
      "[epoch:1, iter:302] Loss: 1.095 | Acc: 38.079% \n",
      "[epoch:1, iter:303] Loss: 1.095 | Acc: 38.284% \n",
      "[epoch:1, iter:304] Loss: 1.095 | Acc: 38.158% \n",
      "[epoch:1, iter:305] Loss: 1.095 | Acc: 38.361% \n",
      "[epoch:1, iter:306] Loss: 1.094 | Acc: 38.562% \n",
      "[epoch:1, iter:307] Loss: 1.095 | Acc: 38.436% \n",
      "[epoch:1, iter:308] Loss: 1.095 | Acc: 38.312% \n",
      "[epoch:1, iter:309] Loss: 1.095 | Acc: 38.511% \n",
      "[epoch:1, iter:310] Loss: 1.095 | Acc: 38.387% \n",
      "[epoch:1, iter:311] Loss: 1.095 | Acc: 38.264% \n",
      "[epoch:1, iter:312] Loss: 1.095 | Acc: 38.462% \n",
      "[epoch:1, iter:313] Loss: 1.095 | Acc: 38.658% \n",
      "[epoch:1, iter:314] Loss: 1.095 | Acc: 38.535% \n",
      "[epoch:1, iter:315] Loss: 1.095 | Acc: 38.413% \n",
      "[epoch:1, iter:316] Loss: 1.094 | Acc: 38.608% \n",
      "[epoch:1, iter:317] Loss: 1.095 | Acc: 38.486% \n",
      "[epoch:1, iter:318] Loss: 1.094 | Acc: 38.679% \n",
      "[epoch:1, iter:319] Loss: 1.095 | Acc: 38.558% \n",
      "[epoch:1, iter:320] Loss: 1.095 | Acc: 38.438% \n",
      "[epoch:1, iter:321] Loss: 1.094 | Acc: 38.629% \n",
      "[epoch:1, iter:322] Loss: 1.094 | Acc: 38.509% \n",
      "[epoch:1, iter:323] Loss: 1.095 | Acc: 38.390% \n",
      "[epoch:1, iter:324] Loss: 1.095 | Acc: 38.272% \n",
      "[epoch:1, iter:325] Loss: 1.095 | Acc: 38.154% \n",
      "[epoch:1, iter:326] Loss: 1.095 | Acc: 38.037% \n",
      "[epoch:1, iter:327] Loss: 1.095 | Acc: 37.920% \n",
      "[epoch:1, iter:328] Loss: 1.095 | Acc: 38.110% \n",
      "[epoch:1, iter:329] Loss: 1.095 | Acc: 37.994% \n",
      "[epoch:1, iter:330] Loss: 1.095 | Acc: 37.879% \n",
      "[epoch:1, iter:331] Loss: 1.095 | Acc: 37.764% \n",
      "[epoch:1, iter:332] Loss: 1.095 | Acc: 37.952% \n",
      "[epoch:1, iter:333] Loss: 1.095 | Acc: 37.838% \n",
      "[epoch:1, iter:334] Loss: 1.095 | Acc: 38.024% \n",
      "[epoch:1, iter:335] Loss: 1.096 | Acc: 37.910% \n",
      "[epoch:1, iter:336] Loss: 1.096 | Acc: 37.798% \n",
      "[epoch:1, iter:337] Loss: 1.096 | Acc: 37.685% \n",
      "[epoch:1, iter:338] Loss: 1.096 | Acc: 37.574% \n",
      "[epoch:1, iter:339] Loss: 1.096 | Acc: 37.758% \n",
      "[epoch:1, iter:340] Loss: 1.095 | Acc: 37.941% \n",
      "[epoch:1, iter:341] Loss: 1.095 | Acc: 37.830% \n",
      "[epoch:1, iter:342] Loss: 1.095 | Acc: 37.719% \n",
      "[epoch:1, iter:343] Loss: 1.095 | Acc: 37.901% \n",
      "[epoch:1, iter:344] Loss: 1.095 | Acc: 37.791% \n",
      "[epoch:1, iter:345] Loss: 1.095 | Acc: 37.681% \n",
      "[epoch:1, iter:346] Loss: 1.095 | Acc: 37.572% \n",
      "[epoch:1, iter:347] Loss: 1.095 | Acc: 37.464% \n",
      "[epoch:1, iter:348] Loss: 1.094 | Acc: 37.644% \n",
      "[epoch:1, iter:349] Loss: 1.095 | Acc: 37.536% \n",
      "[epoch:1, iter:350] Loss: 1.094 | Acc: 37.714% \n",
      "[epoch:1, iter:351] Loss: 1.095 | Acc: 37.607% \n",
      "[epoch:1, iter:352] Loss: 1.095 | Acc: 37.500% \n",
      "[epoch:1, iter:353] Loss: 1.095 | Acc: 37.677% \n",
      "[epoch:1, iter:354] Loss: 1.095 | Acc: 37.571% \n",
      "[epoch:1, iter:355] Loss: 1.095 | Acc: 37.465% \n",
      "[epoch:1, iter:356] Loss: 1.095 | Acc: 37.360% \n",
      "[epoch:1, iter:357] Loss: 1.095 | Acc: 37.255% \n",
      "[epoch:1, iter:358] Loss: 1.095 | Acc: 37.151% \n",
      "[epoch:1, iter:359] Loss: 1.095 | Acc: 37.047% \n",
      "[epoch:1, iter:360] Loss: 1.095 | Acc: 37.222% \n",
      "[epoch:1, iter:361] Loss: 1.095 | Acc: 37.396% \n",
      "[epoch:1, iter:362] Loss: 1.095 | Acc: 37.293% \n",
      "[epoch:1, iter:363] Loss: 1.095 | Acc: 37.466% \n",
      "[epoch:1, iter:364] Loss: 1.095 | Acc: 37.363% \n",
      "[epoch:1, iter:365] Loss: 1.095 | Acc: 37.534% \n",
      "[epoch:1, iter:366] Loss: 1.095 | Acc: 37.705% \n",
      "[epoch:1, iter:367] Loss: 1.094 | Acc: 37.875% \n",
      "[epoch:1, iter:368] Loss: 1.095 | Acc: 37.772% \n",
      "[epoch:1, iter:369] Loss: 1.095 | Acc: 37.669% \n",
      "[epoch:1, iter:370] Loss: 1.095 | Acc: 37.568% \n",
      "[epoch:1, iter:371] Loss: 1.095 | Acc: 37.466% \n",
      "[epoch:1, iter:372] Loss: 1.095 | Acc: 37.366% \n",
      "[epoch:1, iter:373] Loss: 1.095 | Acc: 37.265% \n",
      "[epoch:1, iter:374] Loss: 1.095 | Acc: 37.433% \n",
      "[epoch:1, iter:375] Loss: 1.095 | Acc: 37.333% \n",
      "[epoch:1, iter:376] Loss: 1.095 | Acc: 37.500% \n",
      "[epoch:1, iter:377] Loss: 1.095 | Acc: 37.666% \n",
      "[epoch:1, iter:378] Loss: 1.095 | Acc: 37.831% \n",
      "[epoch:1, iter:379] Loss: 1.094 | Acc: 37.731% \n",
      "[epoch:1, iter:380] Loss: 1.094 | Acc: 37.895% \n",
      "[epoch:1, iter:381] Loss: 1.094 | Acc: 37.795% \n",
      "[epoch:1, iter:382] Loss: 1.094 | Acc: 37.958% \n",
      "[epoch:1, iter:383] Loss: 1.094 | Acc: 38.120% \n",
      "[epoch:1, iter:384] Loss: 1.094 | Acc: 38.021% \n",
      "[epoch:1, iter:385] Loss: 1.094 | Acc: 38.182% \n",
      "[epoch:1, iter:386] Loss: 1.094 | Acc: 38.342% \n",
      "[epoch:1, iter:387] Loss: 1.094 | Acc: 38.243% \n",
      "[epoch:1, iter:388] Loss: 1.093 | Acc: 38.144% \n",
      "[epoch:1, iter:389] Loss: 1.093 | Acc: 38.303% \n",
      "[epoch:1, iter:390] Loss: 1.093 | Acc: 38.462% \n",
      "[epoch:1, iter:391] Loss: 1.093 | Acc: 38.363% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-236:\n",
      "Process Process-43:\n",
      "Process Process-134:\n",
      "Process Process-219:\n",
      "Process Process-23:\n",
      "Process Process-11:\n",
      "Process Process-56:\n",
      "Process Process-14:\n",
      "Process Process-6:\n",
      "Process Process-64:\n",
      "Process Process-91:\n",
      "Process Process-40:\n",
      "Process Process-21:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7efd5a8f35f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dfcc084ab1f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;31m# forward + backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-18e5133f56ea>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-37:\n",
      "Process Process-50:\n",
      "Process Process-217:\n",
      "Process Process-39:\n",
      "Process Process-42:\n",
      "Process Process-128:\n",
      "Process Process-198:\n",
      "Process Process-235:\n",
      "Process Process-99:\n",
      "Process Process-19:\n",
      "Process Process-71:\n",
      "Process Process-111:\n",
      "Process Process-83:\n",
      "Process Process-256:\n",
      "Process Process-52:\n",
      "Process Process-74:\n",
      "Process Process-241:\n",
      "Process Process-25:\n",
      "Process Process-28:\n",
      "Process Process-80:\n",
      "Process Process-85:\n",
      "Traceback (most recent call last):\n",
      "Process Process-242:\n",
      "Process Process-35:\n",
      "Process Process-45:\n",
      "Process Process-73:\n",
      "Process Process-135:\n",
      "Process Process-44:\n",
      "Traceback (most recent call last):\n",
      "Process Process-46:\n",
      "Process Process-255:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-59:\n",
      "Traceback (most recent call last):\n",
      "Process Process-34:\n",
      "Process Process-210:\n",
      "Process Process-240:\n",
      "Process Process-103:\n",
      "Traceback (most recent call last):\n",
      "Process Process-27:\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Process Process-31:\n",
      "Traceback (most recent call last):\n",
      "Process Process-54:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Process Process-121:\n",
      "Process Process-243:\n",
      "Process Process-109:\n",
      "Process Process-82:\n",
      "Process Process-124:\n",
      "Process Process-214:\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Process Process-133:\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Process Process-204:\n",
      "Process Process-215:\n",
      "Process Process-9:\n",
      "Process Process-226:\n",
      "Process Process-245:\n",
      "Process Process-218:\n",
      "Process Process-100:\n",
      "Process Process-203:\n",
      "Process Process-116:\n",
      "Process Process-127:\n",
      "Process Process-246:\n",
      "Process Process-143:\n",
      "Process Process-239:\n",
      "Process Process-234:\n",
      "Process Process-224:\n",
      "Traceback (most recent call last):\n",
      "Process Process-113:\n",
      "Process Process-229:\n",
      "Process Process-228:\n",
      "Process Process-61:\n",
      "Process Process-92:\n",
      "Process Process-208:\n",
      "Traceback (most recent call last):\n",
      "Process Process-125:\n",
      "Process Process-211:\n",
      "Process Process-120:\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "Traceback (most recent call last):\n",
      "Process Process-233:\n",
      "Process Process-213:\n",
      "Traceback (most recent call last):\n",
      "Process Process-216:\n",
      "Process Process-238:\n",
      "Process Process-231:\n",
      "Traceback (most recent call last):\n",
      "Process Process-123:\n",
      "Traceback (most recent call last):\n",
      "Process Process-24:\n",
      "Process Process-60:\n",
      "Process Process-88:\n",
      "Traceback (most recent call last):\n",
      "Process Process-17:\n",
      "Process Process-58:\n",
      "Process Process-62:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-249:\n",
      "Process Process-20:\n",
      "Process Process-97:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-220:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "Process Process-3:\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "Traceback (most recent call last):\n",
      "Process Process-57:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-93:\n",
      "Process Process-237:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/miniconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-122:\n",
      "Process Process-252:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()  #损失函数为交叉熵，多用于多分类问题\n",
    "\n",
    "params_all = [p for p in net.parameters() if p.requires_grad]\n",
    "base_params = list(map(id, net.backbone.parameters()))\n",
    "logits_params = filter(lambda p: id(p) not in base_params, params_all)\n",
    "pre_epoch = 0\n",
    "decay = 1\n",
    "# 训练\n",
    "if __name__ == \"__main__\":\n",
    "    best_acc = 75  \n",
    "    print(\"Start Training, Resnet50-FPN!\") \n",
    "    with open(\"acc_800.txt\", \"w\") as f:\n",
    "        with open(\"log_800.txt\", \"w\")as f2:\n",
    "            for epoch in range(pre_epoch, EPOCH):\n",
    "                print('\\nEpoch: %d' % (epoch + 1))\n",
    "                net.train()\n",
    "                sum_loss = 0.0\n",
    "                correct = 0.0\n",
    "                total = 0.0\n",
    "                if epoch < 1:\n",
    "                    lr_backbone = 0\n",
    "                    lr_roialign = 1e-3                    \n",
    "                else:\n",
    "                    lr_backbone = 1e-3\n",
    "                    lr_roialign = 1e-3\n",
    "                    decay = decay * 0.8\n",
    "                params = [{'params': logits_params, 'lr':decay*lr_roialign},\n",
    "                            {'params': net.backbone.parameters(), 'lr':decay*lr_backbone}]   \n",
    "                \n",
    "                optimizer = optim.SGD(params, momentum=0.2, weight_decay = 1e-4) \n",
    "                \n",
    "                for i, data in enumerate(trainloader, 0):\n",
    "                    length = len(trainloader)\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward + backward\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    sum_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels.data).cpu().sum()\n",
    "                    print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n",
    "                          % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "                    f2.write('%03d  %05d |Loss: %.03f | Acc: %.3f%% '\n",
    "                          % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "                    f2.write('\\n')\n",
    "                    f2.flush()\n",
    "                torch.cuda.empty_cache()\n",
    "                # 每训练完一个epoch测试一下准确率\n",
    "                print(\"Waiting Test!\")\n",
    "                with torch.no_grad():\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    class_correct = list(0. for i in range(3)) \n",
    "                    class_total = list(0. for i in range(3))   \n",
    "                    for data in testloader:\n",
    "                        net.eval()\n",
    "                        images, labels = data\n",
    "                        images, labels = images.to(device), labels.to(device)\n",
    "                        outputs = net(images)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum()\n",
    "                        c = (predicted == labels).squeeze()\n",
    "                        label = labels   \n",
    "                        class_correct[label] += c\n",
    "                        class_total[label] += 1\n",
    "                    for i in range(3):\n",
    "                        print('Accuracy of %5s : %2d %%' % (\n",
    "                            classes[i], 100 * class_correct[i] // class_total[i]))\n",
    "                    print('测试分类准确率为：%.3f%%' % (100 * correct // total))\n",
    "                    acc = 100. * correct / total\n",
    "                    # 将每次测试结果实时写入acc.txt文件中\n",
    "                    f.write(\"EPOCH=%03d,Accuracy= %.3f%%\" % (epoch + 1, acc))\n",
    "                    f.write('\\n')\n",
    "                    f.flush()\n",
    "                    # 记录最佳测试分类准确率并写入best_acc.txt文件中\n",
    "                    if acc > best_acc:\n",
    "                        f3 = open(\"best_acc_800.txt\", \"w\")\n",
    "                        print('Saving model......')\n",
    "                        torch.save(net.state_dict(), 'GAF_2_best_net_image_800.pth')\n",
    "                        f3.write(\"EPOCH=%d,best_acc= %.3f%%\" % (epoch + 1, acc))\n",
    "                        f3.close()\n",
    "                        best_acc = acc\n",
    "            print(\"Training Finished, TotalEPOCH=%d\" % EPOCH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
