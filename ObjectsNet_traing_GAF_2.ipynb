{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os,torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import argparse\n",
    "import torchfile\n",
    "from PIL import Image\n",
    "from torchvision import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotiWDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, BoW_filelist, Train_Flag):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filelist: List of names of image/feature files.\n",
    "            root_dir: Dataset directory\n",
    "            transform (callable, optional): Optional transformer to be applied\n",
    "                                            on an image sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.BoW_filelist = BoW_filelist\n",
    "        self.Train_Flag = Train_Flag\n",
    "\n",
    "        \n",
    "        neg_filelist = sorted(os.listdir(BoW_filelist + 'Negative/'))\n",
    "        neu_filelist = sorted(os.listdir(BoW_filelist + 'Neutral/'))\n",
    "        pos_filelist = sorted(os.listdir(BoW_filelist + 'Positive/'))\n",
    "        \n",
    "        self.label = []\n",
    "        neg_label = np.array(np.zeros(len(neg_filelist)),dtype = np.int64)\n",
    "        neu_label = np.array(np.ones(len(neu_filelist)),dtype = np.int64)\n",
    "        pos_label = np.array(2*np.ones(len(pos_filelist)),dtype = np.int64)\n",
    "        \n",
    "        self.label.extend(neg_label)\n",
    "        self.label.extend(neu_label)\n",
    "        self.label.extend(pos_label)\n",
    "        \n",
    "        self.file_paths = []\n",
    "        \n",
    "        for f in neg_filelist:\n",
    "            path = os.path.join(self.BoW_filelist,'Negative/',f)\n",
    "            self.file_paths.append(path)\n",
    "        for f in neu_filelist:\n",
    "            path = os.path.join(self.BoW_filelist,'Neutral/',f)\n",
    "            self.file_paths.append(path)\n",
    "        for f in pos_filelist:\n",
    "            path = os.path.join(self.BoW_filelist,'Positive/',f)\n",
    "            self.file_paths.append(path)       \n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.file_paths)) \n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        BoW_path = self.file_paths[idx]\n",
    "        BoW = np.load(BoW_path)\n",
    "        if self.Train_Flag is True:\n",
    "            BoW_feature = BoW['train_BoW']\n",
    "\n",
    "        else:\n",
    "            BoW_feature = BoW['val_BoW']   \n",
    "            \n",
    "        label = self.label[idx]\n",
    "    \n",
    "        BoW_feature = torch.from_numpy(BoW_feature)\n",
    "        BoW_feature = BoW_feature.to(torch.float32) \n",
    "        #SAMPLE\n",
    "        return BoW_feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EPOCH = 50   \n",
    "pre_epoch = 0  \n",
    "LR = 0.001        \n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch GAF_2 Training')\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "\n",
    "classes = ('Negative', 'Neutral', 'Positive')\n",
    "\n",
    "\n",
    "train_dataset = EmotiWDataset(BoW_filelist='../Bag_of_Visual_Words/GAF_2_Train/',Train_Flag = True)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, shuffle=True, batch_size=256, num_workers=0)\n",
    "\n",
    "val_dataset = EmotiWDataset(BoW_filelist='../Bag_of_Visual_Words/GAF_2_Val/',Train_Flag = False)\n",
    "\n",
    "validationloader = DataLoader(val_dataset, shuffle =False, batch_size = 512, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1_layer = nn.Sequential(nn.Linear(in_features=1600, out_features=4096), nn.ReLU(), nn.Dropout(0.5)) \n",
    "        self.fc2_layer = nn.Sequential(nn.Linear(in_features=4096, out_features=128), nn.ReLU(), nn.Dropout(0.5))\n",
    "        self.fc3_layer = nn.Sequential(nn.Linear(in_features=128, out_features=3)) \n",
    "    def forward(self, x):\n",
    "        x = self.fc1_layer(x)\n",
    "        x = self.fc2_layer(x)\n",
    "        x = self.fc3_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "[epoch:1, iter:1] Loss: 1.107 | Acc: 26.562% \n",
      "[epoch:1, iter:2] Loss: 1.103 | Acc: 30.078% \n",
      "[epoch:1, iter:3] Loss: 1.101 | Acc: 32.422% \n",
      "[epoch:1, iter:4] Loss: 1.102 | Acc: 31.348% \n",
      "[epoch:1, iter:5] Loss: 1.103 | Acc: 31.016% \n",
      "[epoch:1, iter:6] Loss: 1.102 | Acc: 31.250% \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c218b530ae76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0;31m# 准备数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-3ac7a14e0e2a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mBoW_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mBoW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBoW_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain_Flag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mBoW_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_BoW'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/miniconda3/envs/pytorch/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0m_ZIP_SUFFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb'PK\\x05\\x06'\u001b[0m \u001b[0;31m# empty zip files start with this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;31m# If the file size is less than N, we need to make sure not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# to seek past the beginning of the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()  #损失函数为交叉熵，多用于多分类问题\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-1) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "# 训练\n",
    "if __name__ == \"__main__\":\n",
    "    best_acc = 30  #2 \n",
    "    with open(\"acc.txt\", \"w\") as f:\n",
    "        with open(\"log.txt\", \"w\")as f2:\n",
    "            for epoch in range(EPOCH):\n",
    "                print('\\nEpoch: %d' % (epoch + 1))\n",
    "                net.train()\n",
    "                sum_loss = 0.0\n",
    "                correct = 0.0\n",
    "                total = 0.0\n",
    "\n",
    "                for i, data in enumerate(trainloader, 0):\n",
    "                    torch.cuda.empty_cache()\n",
    "                    # 准备数据\n",
    "                    length = len(trainloader)\n",
    "                    BoW_feature, labels = data\n",
    "                    one_hot = torch.zeros(labels.shape[0], 3).scatter_(1, labels.unsqueeze(1), 1) \n",
    "                    one_hot = one_hot.to(device)                    \n",
    "                    BoW_feature, labels = BoW_feature.to(device),labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = net(BoW_feature)\n",
    "                    \n",
    "                    # forward + backward\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # 每训练1个batch打印一次loss和准确率\n",
    "                    sum_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels.data).cpu().sum()\n",
    "                    print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n",
    "                          % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "                    f2.write('%03d  %05d |Loss: %.03f | Acc: %.3f%% |'\n",
    "                          % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "                    f2.write('\\n')\n",
    "                    f2.flush()\n",
    "  \n",
    "                scheduler.step()\n",
    "                torch.cuda.empty_cache()\n",
    "                # 每训练完一个epoch测试一下准确率\n",
    "                print(\"Waiting Test!\")\n",
    "                with torch.no_grad():\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    class_correct = list(0. for j in range(3)) # 定义一个存储每类中测试正确的个数的 列表，初始化为0\n",
    "                    class_total = list(0. for j in range(3))   # 定义一个存储每类中测试总数的个数的 列表，初始化为0\n",
    "                    for data in validationloader:\n",
    "                        net.eval()\n",
    "                        BoW_feature, labels = data\n",
    "                        BoW_feature, labels = BoW_feature.to(device),labels.to(device)                       \n",
    "                        outputs = net(BoW_feature)\n",
    "                        torch.cuda.empty_cache()\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        c = (predicted == labels).squeeze() \n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum()                       \n",
    "                        if  labels.shape[0] == 1:\n",
    "                            class_correct[labels] += c\n",
    "                        else:\n",
    "                            for j in range(labels.shape[0]):      # 因为每个batch都有多张图片，所以还需要一个小循环\n",
    "                                label = labels[j]   # 对各个类的进行各自累加\n",
    "                                class_correct[label] += c[j]\n",
    "                                class_total[label] += 1    \n",
    "                        \n",
    "                    for j in range(3):\n",
    "                        print('Accuracy of %5s : %.3f %%' % (\n",
    "                                classes[j], 100 * class_correct[j] // class_total[j]))\n",
    "                    print('验证集分类准确率为：%.3f%%' % (100 * correct // total))\n",
    "                    acc = 100. * correct / total\n",
    "                    # 将每次测试结果实时写入acc.txt文件中\n",
    "                    f.write(\"EPOCH=%03d,Accuracy= %.3f%%\" % (epoch + 1, acc))\n",
    "                    f.write('\\n')\n",
    "                    f.flush()\n",
    "                    if acc > best_acc:\n",
    "                        print('Saving model......')\n",
    "                        #torch.save(net.state_dict(), '%snet_%03d.pth' % (args.outf, epoch + 1))\n",
    "                        torch.save(net.state_dict(), 'GAF_2_best_net_BoW.pth')\n",
    "                        # 记录最佳测试分类准确率并写入best_acc.txt文件中\n",
    "                        f3 = open(\"best_acc.txt\", \"w\")\n",
    "                        f3.write(\"EPOCH=%d,best_acc= %.3f%%\" % (epoch + 1, acc))\n",
    "                        f3.close()\n",
    "                        best_acc = acc\n",
    "\n",
    "            print(\"Training Finished, TotalEPOCH=%d\" % EPOCH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
